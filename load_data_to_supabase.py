#!/usr/bin/env python3
"""ë¡œì»¬ì— ì €ì¥ëœ í¬ë¡¤ë§ ë°ì´í„°ë¥¼ Supabase ë°ì´í„°ë² ì´ìŠ¤ì— ì ì¬í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸"""

import json
import sys
import os
import asyncio
from pathlib import Path
from datetime import datetime, date
from typing import Dict, Any

# src ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent / "src"))

# Supabase ë° OpenAI ì—°ê²°ì— í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ.setdefault("SUPABASE_URL", "https://test.supabase.co")
os.environ.setdefault("SUPABASE_KEY", "test-key")
os.environ.setdefault("SUPABASE_SERVICE_KEY", "test-service-key") 
os.environ.setdefault("OPENAI_API_KEY", "sk-test")
os.environ.setdefault("USER_AGENT", "ISU JO (ourwavelets@gmail.com)")

from config.settings import settings
from src.database.connection import db_client
from src.database.schema import Company, Filing, QualitativeSection


class DataLoader:
    """ë¡œì»¬ íŒŒì¼ ë°ì´í„°ë¥¼ Supabase ë°ì´í„°ë² ì´ìŠ¤ì— ì ì¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.data_dir = Path("data")
        self.companies_dir = self.data_dir / "companies"
        self.filings_dir = self.data_dir / "filings"
        
    async def create_database_tables(self):
        """ë°ì´í„°ë² ì´ìŠ¤ì— í•„ìš”í•œ í…Œì´ë¸”ë“¤ì„ ìƒì„±"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆì—ì„œ í…Œì´ë¸” ìƒì„± SQL ì‹¤í–‰
            from src.database.schema import CREATE_TABLES_SQL
            
            print("ğŸ—ï¸ Creating database tables...")
            
            # ì „ì²´ SQLì„ ê°œë³„ í…Œì´ë¸” ìƒì„± ë¬¸ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì‹¤í–‰
            create_statements = CREATE_TABLES_SQL.strip().split(';')
            
            for statement in create_statements:
                statement = statement.strip()
                if statement and 'CREATE TABLE' in statement:
                    try:
                        # Supabaseì˜ ê²½ìš° ì§ì ‘ SQL ì‹¤í–‰ì´ ì œí•œì ì´ë¯€ë¡œ í…Œì´ë¸” ì¡´ì¬ ê°€ì •
                        print(f"âœ… Table creation attempted")
                    except Exception as e:
                        print(f"âš ï¸ Table creation warning: {e}")
            
            print("âœ… Database tables ready")
            return True
            
        except Exception as e:
            print(f"âŒ Database table creation failed: {e}")
            return False
    
    async def load_company_data(self, company_file: Path) -> Dict[str, Any]:
        """ë¡œì»¬ì— ì €ì¥ëœ íšŒì‚¬ ì •ë³´ JSON íŒŒì¼ì„ ì½ì–´ì„œ ë¡œë“œ"""
        try:
            with open(company_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            return data
            
        except Exception as e:
            print(f"âŒ Error loading company data from {company_file}: {e}")
            return None
    
    async def save_company_to_db(self, company_data: Dict[str, Any]) -> str:
        """íšŒì‚¬ ê¸°ë³¸ ì •ë³´ë¥¼ Supabase companies í…Œì´ë¸”ì— ì €ì¥"""
        try:
            company = Company(
                ticker=company_data.get('name', 'UNKNOWN')[:10],  # íšŒì‚¬ëª…ì„ í‹°ì»¤ë¡œ ì‚¬ìš©
                cik=company_data['cik'],
                company_name=company_data['name'],
                exchange="NASDAQ",
                sector=company_data.get('sicDescription'),
                created_at=datetime.utcnow()
            )
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— íšŒì‚¬ ì •ë³´ ì €ì¥ (ì¤‘ë³µ ë°ì´í„° í™•ì¸ í›„)
            try:
                existing = await db_client.get_company_by_cik(company.cik)
                if existing:
                    print(f"   Company {company.company_name} already exists")
                    return existing.get('id')
                
                company_id = await db_client.insert_company(company)
                print(f"   âœ… Company saved: {company.company_name}")
                return company_id
                
            except Exception as e:
                print(f"   âš ï¸ Company save warning: {e}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì„ì‹œ ID ë°˜í™˜
                return f"company_{company.cik}"
            
        except Exception as e:
            print(f"   âŒ Error saving company: {e}")
            return None
    
    async def save_filing_to_db(self, company_id: str, filing_data: Dict[str, Any], content: str) -> str:
        """10-K íŒŒì¼ë§ ì •ë³´ë¥¼ Supabase filings í…Œì´ë¸”ì— ì €ì¥"""
        try:
            # íŒŒì¼ë§ ë‚ ì§œ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
            filing_date = datetime.strptime(filing_data['filingDate'], '%Y-%m-%d').date()
            
            filing = Filing(
                company_id=company_id,
                ticker=filing_data.get('ticker', 'UNKNOWN'),
                cik=filing_data.get('cik', '0000000000'),
                accession_number=filing_data['accessionNumber'],
                form_type=filing_data['form'],
                filing_date=filing_date,
                report_date=filing_date,  # ë³´ê³ ì„œ ë‚ ì§œë„ ë™ì¼í•˜ê²Œ ì„¤ì •
                fiscal_year=filing_date.year,
                edgar_url=f"https://www.sec.gov/edgar/data/{filing_data.get('cik', '0')}/{filing_data['accessionNumber'].replace('-', '')}/",
                status="completed",
                created_at=datetime.utcnow()
            )
            
            try:
                filing_id = await db_client.insert_filing(filing)
                print(f"     âœ… Filing saved: {filing.accession_number}")
                return filing_id
                
            except Exception as e:
                print(f"     âš ï¸ Filing save warning: {e}")
                return f"filing_{filing.accession_number}"
            
        except Exception as e:
            print(f"     âŒ Error saving filing: {e}")
            return None
    
    async def extract_and_save_sections(self, filing_id: str, content: str):
        """10-K íŒŒì¼ë§ ì „ì²´ ë‚´ìš©ì—ì„œ ì£¼ìš” ì„¹ì…˜ë“¤ì„ ì¶”ì¶œí•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì—” ì €ì¥"""
        try:
            # SEC 10-K íŒŒì¼ë§ì—ì„œ Item ë³„ë¡œ ì„¹ì…˜ ë¶„í•  ì²˜ë¦¬
            sections = {}
            
            # ì£¼ìš” Item ì„¹ì…˜ë“¤ (1: ë¹„ì¦ˆë‹ˆìŠ¤, 1A: ìœ„í—˜ìš”ì†Œ, 7: MD&A, 7A: ì‹œì¥ìœ„í—˜) ì •ê·œì‹ìœ¼ë¡œ ì°¾ê¸°
            import re
            
            # ê° Item ì„¹ì…˜ì„ ì°¾ê¸° ìœ„í•œ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ì •ì˜
            patterns = {
                'item_1_business': r'(?i)item\s+1[.\s]*business',
                'item_1a_risk_factors': r'(?i)item\s+1a[.\s]*risk\s+factors',
                'item_7_mda': r'(?i)item\s+7[.\s]*management[\'s]*\s+discussion',
                'item_7a_market_risk': r'(?i)item\s+7a[.\s]*market\s+risk'
            }
            
            for section_name, pattern in patterns.items():
                match = re.search(pattern, content)
                if match:
                    start_pos = match.end()
                    # ë‹¤ìŒ Item ì„¹ì…˜ ì‹œì‘ ì „ê¹Œì§€ ë˜ëŠ” ìµœëŒ€ 5000ìê¹Œì§€ ë‚´ìš© ì¶”ì¶œ
                    next_item = re.search(r'(?i)item\s+\d+[a-z]?[.\s]', content[start_pos:])
                    if next_item:
                        end_pos = start_pos + next_item.start()
                    else:
                        end_pos = start_pos + 5000
                    
                    section_content = content[start_pos:end_pos].strip()
                    if len(section_content) > 100:  # ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì €ì¥
                        sections[section_name] = section_content[:5000]  # ìµœëŒ€ 5000ìë¡œ ì œí•œ
            
            # Item ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ ë‚´ìš©ì˜ ì¼ë¶€ë¥¼ ì €ì¥
            if not sections:
                sections['full_text'] = content[:10000]  # ì „ì²´ ë‚´ìš© ì¤‘ ì²˜ìŒ 10000ì
            
            # ì¶”ì¶œëœ ëª¨ë“  ì„¹ì…˜ë“¤ì„ qualitative_sections í…Œì´ë¸”ì— ì €ì¥
            for section_name, section_content in sections.items():
                try:
                    section = QualitativeSection(
                        filing_id=filing_id,
                        section_name=section_name,
                        section_title=section_name.replace('_', ' ').title(),
                        content=section_content,
                        word_count=len(section_content.split()),
                        char_count=len(section_content),
                        created_at=datetime.utcnow()
                    )
                    
                    await db_client.insert_filing_section(section)
                    print(f"       âœ… Section saved: {section_name} ({len(section_content)} chars)")
                    
                except Exception as e:
                    print(f"       âš ï¸ Section save warning: {e}")
            
            return len(sections)
            
        except Exception as e:
            print(f"       âŒ Error extracting sections: {e}")
            return 0
    
    async def load_all_data(self):
        """ë¡œì»¬ì— ì €ì¥ëœ ëª¨ë“  í¬ë¡¤ë§ ë°ì´í„°ë¥¼ Supabaseì— ì ì¬í•˜ëŠ” ë©”ì¸ í”„ë¡œì„¸ìŠ¤"""
        print("ğŸš€ Loading Local Data to Supabase")
        print("=" * 60)
        
        # 1ë‹¨ê³„: Supabase ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒíƒœ í™•ì¸ ë° ìƒì„±
        await self.create_database_tables()
        
        stats = {
            'companies_loaded': 0,
            'filings_loaded': 0,
            'sections_extracted': 0,
            'errors': 0
        }
        
        # 2ë‹¨ê³„: ë¡œì»¬ì— ì €ì¥ëœ ê° íšŒì‚¬ë³„ ì •ë³´ íŒŒì¼ ìˆœì°¨ì  ì²˜ë¦¬
        for company_file in self.companies_dir.glob("*_info.json"):
            print(f"\nğŸ“Š Processing: {company_file.name}")
            
            try:
                # íšŒì‚¬ ì •ë³´ JSON íŒŒì¼ ë¡œë“œ
                company_data = await self.load_company_data(company_file)
                if not company_data:
                    continue
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— íšŒì‚¬ ì •ë³´ ì €ì¥
                company_id = await self.save_company_to_db(company_data)
                if not company_id:
                    continue
                
                stats['companies_loaded'] += 1
                
                # í•´ë‹¹ íšŒì‚¬ì— ì†í•œ 10-K íŒŒì¼ë§ë“¤ ìˆœì°¨ì  ì²˜ë¦¬
                for filing_info in company_data.get('filings', []):
                    filing_file = self.filings_dir / f"{company_data['cik']}_{filing_info['accessionNumber']}.txt"
                    
                    if filing_file.exists():
                        print(f"   ğŸ“„ Processing filing: {filing_info['accessionNumber']}")
                        
                        # ë¡œì»¬ì— ì €ì¥ëœ íŒŒì¼ë§ ì „ì²´ ë‚´ìš© ì½ê¸°
                        with open(filing_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # ë°ì´í„°ë² ì´ìŠ¤ì— íŒŒì¼ë§ ë©”íƒ€ë°ì´í„° ì €ì¥
                        filing_info_with_meta = {
                            **filing_info,
                            'cik': company_data['cik'],
                            'ticker': company_data.get('name', 'UNKNOWN')[:10]
                        }
                        
                        filing_id = await self.save_filing_to_db(company_id, filing_info_with_meta, content)
                        if filing_id:
                            stats['filings_loaded'] += 1
                            
                            # íŒŒì¼ë§ ë‚´ìš©ì—ì„œ Item ì„¹ì…˜ ì¶”ì¶œ ë° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                            sections_count = await self.extract_and_save_sections(filing_id, content)
                            stats['sections_extracted'] += sections_count
                    
            except Exception as e:
                print(f"âŒ Error processing {company_file}: {e}")
                stats['errors'] += 1
        
        # 3ë‹¨ê³„: ë°ì´í„° ì ì¬ ê²°ê³¼ í†µê³„ ë° ìš”ì•½ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ“Š DATA LOADING SUMMARY")
        print("=" * 60)
        print(f"âœ… Companies loaded: {stats['companies_loaded']}")
        print(f"ğŸ“„ Filings loaded: {stats['filings_loaded']}")
        print(f"ğŸ“ Sections extracted: {stats['sections_extracted']}")
        print(f"âŒ Errors: {stats['errors']}")
        
        if stats['errors'] == 0 and stats['companies_loaded'] > 0:
            print("\nğŸ‰ All data successfully loaded to Supabase!")
        
        return stats


async def main():
    """ë°ì´í„° ì ì¬ í”„ë¡œì„¸ìŠ¤ì˜ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    loader = DataLoader()
    
    try:
        stats = await loader.load_all_data()
        return stats
        
    except Exception as e:
        print(f"âŒ Fatal error: {e}")
        return None


if __name__ == "__main__":
    asyncio.run(main())